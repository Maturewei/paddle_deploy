import os
import warnings
import logging

# åœ¨å¯¼å…¥streamlitä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡å’Œæ—¥å¿—çº§åˆ«
os.environ['STREAMLIT_SERVER_HEADLESS'] = 'true'
# ç¦ç”¨XSRFä¿æŠ¤ä»¥é¿å…CORSé…ç½®å†²çªè­¦å‘Š
os.environ['STREAMLIT_SERVER_ENABLE_XSRF_PROTECTION'] = 'false'
os.environ['STREAMLIT_SERVER_ENABLE_CORS'] = 'false'

# è®¾ç½®æ—¥å¿—çº§åˆ«æ¥æŠ‘åˆ¶è­¦å‘Š
logging.getLogger('streamlit').setLevel(logging.ERROR)
logging.getLogger('streamlit.runtime').setLevel(logging.ERROR)
logging.getLogger('streamlit.runtime.scriptrunner').setLevel(logging.ERROR)

# å¿½ç•¥æ‰€æœ‰è­¦å‘Š
warnings.filterwarnings("ignore")
warnings.simplefilter("ignore")

import streamlit as st
import cv2
import numpy as np
import tempfile
import time
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
from datetime import datetime
import pandas as pd

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŸºäºé£æ¡¨PaddleDetectionçš„æ™ºèƒ½é›¶å”®ç³»ç»Ÿ",
    page_icon="https://paddlepaddle-org-cn.cdn.bcebos.com/paddle-site-front/static/media/paddlelogo.0b483fa7.png",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    .sub-header {
        font-size: 1.5rem;
        color: #ff7f0e;
        margin: 1rem 0;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
        margin: 0.5rem 0;
    }
    .success-message {
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #c3e6cb;
    }
    .warning-message {
        background-color: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #ffeaa7;
    }
</style>
""", unsafe_allow_html=True)

# å¯¼å…¥å®‰å…¨æ¨¡å‹åŠ è½½å™¨
from model_loader import load_model_safe, get_model_loader

# å¯¼å…¥å¤šäººæ‹¿å–æ£€æµ‹å™¨
from multi_person_detector import MultiPersonDetector

# ========================================
# ğŸ“ æ¨¡å‹è·¯å¾„é…ç½®åŒº
# ========================================
# è¯·åœ¨ä¸‹æ–¹ä¿®æ”¹æ¨¡å‹æ–‡ä»¶å¤¹çš„è·¯å¾„
# æ¨¡å‹æ–‡ä»¶å¤¹å¿…é¡»åŒ…å«ä»¥ä¸‹3ä¸ªæ–‡ä»¶ï¼š
# - infer_cfg.yml
# - model.pdmodel
# - model.pdiparams

# æ–¹å¼1ï¼šä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆæ¨èï¼‰
MODEL_PATH = "../output_inference"

# æ–¹å¼2ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„
#MODEL_PATH = r"D:\output_inference"


# éªŒè¯å¹¶è®¾ç½®æ¨¡å‹è·¯å¾„
def validate_and_set_model_path(path):
    """éªŒè¯æ¨¡å‹è·¯å¾„å¹¶è¿”å›æ ‡å‡†åŒ–çš„è·¯å¾„"""
    # æ ‡å‡†åŒ–è·¯å¾„
    normalized_path = os.path.normpath(os.path.abspath(path))
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(normalized_path):
        return None, f"è·¯å¾„ä¸å­˜åœ¨: {normalized_path}"
    
    # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
    required_files = ['infer_cfg.yml', 'model.pdmodel', 'model.pdiparams']
    missing_files = []
    
    for file_name in required_files:
        file_path = os.path.join(normalized_path, file_name)
        if not os.path.exists(file_path):
            missing_files.append(file_name)
    
    if missing_files:
        return None, f"ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {', '.join(missing_files)}"
    
    return normalized_path, None

# éªŒè¯æ¨¡å‹è·¯å¾„
model_path, error_msg = validate_and_set_model_path(MODEL_PATH)

# ä¸»æ ‡é¢˜
st.markdown('<h1 class="main-header">PaddlePickUp: è®©æ™ºèƒ½é›¶å”®"çœ‹å¾—æ¸…ï¼Œæ•°å¾—æ˜"</h1>', unsafe_allow_html=True)

# ä¾§è¾¹æ é…ç½®
st.sidebar.markdown("## âš™ï¸ ç³»ç»Ÿé…ç½®")

# æ˜¾ç¤ºæ¨¡å‹è·¯å¾„ä¿¡æ¯
st.sidebar.markdown("### ğŸ“ æ¨¡å‹é…ç½®")
if model_path:
    st.sidebar.success("âœ… æ¨¡å‹è·¯å¾„å·²é…ç½®")
else:
    st.sidebar.error("âŒ æ¨¡å‹è·¯å¾„é…ç½®é”™è¯¯")
    st.sidebar.error(error_msg)
    st.sidebar.warning("âš ï¸ è¯·åœ¨ä»£ç ä¸­æ­£ç¡®é…ç½® MODEL_PATH")
    st.sidebar.code("MODEL_PATH = '../output_inference'", language="python")

# æ¨¡å‹å‚æ•°é…ç½®
st.sidebar.markdown("## ğŸ›ï¸ é¢„æµ‹å‚æ•°")
confidence_threshold = st.sidebar.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.5, 0.01)

# è§†é¢‘æ£€æµ‹å‚æ•°ï¼ˆç»Ÿä¸€ä½¿ç”¨å¤šäººæ£€æµ‹ç®—æ³•ï¼Œå…¼å®¹å•äººåœºæ™¯ï¼‰
st.sidebar.markdown("### ğŸ¯ è§†é¢‘æ£€æµ‹å‚æ•°")
multi_action_window = st.sidebar.slider("åŠ¨ä½œçª—å£å¤§å°", 10, 100, 80, help="æ£€æµ‹åŠ¨ä½œçš„æ—¶é—´çª—å£ï¼ˆå¸§æ•°ï¼‰")
multi_arm_thresh = st.sidebar.slider("æ‰‹è‡‚æ£€æµ‹é˜ˆå€¼", 1, 10, 3, help="è§¦å‘æ£€æµ‹æ‰€éœ€çš„æ‰‹è‡‚å‡ºç°æ¬¡æ•°")
multi_handGoods_thresh = st.sidebar.slider("æ‰‹éƒ¨å•†å“æ£€æµ‹é˜ˆå€¼", 1, 10, 2, help="ç¡®è®¤æ‹¿å–æ‰€éœ€çš„æ‰‹éƒ¨å•†å“å‡ºç°æ¬¡æ•°")
multi_arm_miss_limit = st.sidebar.slider("æ‰‹è‡‚æ¶ˆå¤±é™åˆ¶", 1, 10, 4, help="å…è®¸æ‰‹è‡‚æš‚æ—¶æ¶ˆå¤±çš„å¸§æ•°")
multi_cooldown_limit = st.sidebar.slider("å†·å´é™åˆ¶", 1, 20, 5, help="æ‹¿å–åŠ¨ä½œåçš„å†·å´å¸§æ•°")
multi_iou_threshold = st.sidebar.slider("IoUåŒ¹é…é˜ˆå€¼", 0.1, 0.5, 0.25, 0.01, help="æ£€æµ‹æ¡†åŒ¹é…çš„IoUé˜ˆå€¼")

# è¡Œåˆ—ç»Ÿè®¡å‚æ•°
st.sidebar.markdown("### ğŸ—„ï¸ è¡Œåˆ—ç»Ÿè®¡å‚æ•°")
position_confidence_threshold = st.sidebar.slider(
    "ä½ç½®è¯†åˆ«ç½®ä¿¡åº¦é˜ˆå€¼", 
    0.3, 0.9, 0.6, 0.05, 
    help="åªä¿å­˜ç½®ä¿¡åº¦é«˜äºæ­¤é˜ˆå€¼çš„è¡Œåˆ—ä½ç½®æ•°æ®ï¼Œç¡®ä¿ç»Ÿè®¡å‡†ç¡®æ€§"
)

# æ€§èƒ½ä¼˜åŒ–é€‰é¡¹
st.sidebar.markdown("## âš¡ æ€§èƒ½è®¾ç½®")
resize_display = st.sidebar.checkbox("å¯ç”¨æ˜¾ç¤ºä¼˜åŒ–", value=True, help="é™ä½æ˜¾ç¤ºåˆ†è¾¨ç‡ä»¥æé«˜æ€§èƒ½")
video_quality = st.sidebar.slider("è§†é¢‘è´¨é‡", 70, 100, 95, help="æ•°å€¼è¶Šé«˜è§†é¢‘è´¨é‡è¶Šå¥½ï¼Œä½†æ–‡ä»¶è¶Šå¤§")
realtime_display = st.sidebar.checkbox("å®æ—¶æ˜¾ç¤ºæ£€æµ‹è¿‡ç¨‹", value=True, help="å¯ç”¨åä¼šå®æ—¶æ˜¾ç¤ºæ¯ä¸€å¸§çš„æ£€æµ‹ç»“æœ")

# å¯¼å…¥å­—ä½“å·¥å…·
from font_utils import safe_draw_text

# é¢œè‰²ä½ç½®æ˜ å°„è¡¨ï¼ˆå‚è€ƒæ™ºèƒ½æŸœç³»ç»Ÿï¼‰
COLOR_POSITION_MAP = {
    "argent": (1, 1), "yellow": (2, 1), "green": (3, 1),
    "grey": (4, 1), "orange": (5, 1), "cyan": (6, 1),
    "black": (1, 2), "scarlet": (2, 2), "red": (3, 2),
    "blue": (4, 2), "purple": (5, 2), "darkBlue": (6, 2)
}

def draw_chinese_text(img, text, position, font_path="SimHei.ttf", font_size=32, color=(0, 255, 0)):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶ä¸­æ–‡æ–‡å­—"""
    return safe_draw_text(img, text, position, font_size, color)

def format_timestamp(frame_idx, fps):
    """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
    total_millis = int((frame_idx / fps) * 1000)
    seconds = total_millis // 1000
    millis = total_millis % 1000
    minutes = seconds // 60
    hours = minutes // 60
    return f"{hours:02d}.{minutes%60:02d}.{seconds%60:02d}.{millis:03d}"

def analyze_drawer_colors(boxes_dict, arm_boxes, hand_boxes):
    """
    åˆ†ææ£€æµ‹æ¡†ä¸­çš„æŠ½å±‰é¢œè‰²ï¼Œåˆ¤æ–­æ‹¿å–çš„æ˜¯å“ªä¸€è¡Œå“ªä¸€åˆ—çš„å•†å“
    
    Args:
        boxes_dict: å­—å…¸ï¼Œkeyä¸ºæ ‡ç­¾åï¼Œvalueä¸ºæ£€æµ‹æ¡†åˆ—è¡¨
        arm_boxes: æ‰‹è‡‚æ£€æµ‹æ¡†åˆ—è¡¨
        hand_boxes: æ‰‹æŒå•†å“æ£€æµ‹æ¡†åˆ—è¡¨
    
    Returns:
        detected_positions: æ£€æµ‹åˆ°çš„ä½ç½®åˆ—è¡¨ [(row, col, color, score), ...]
    """
    detected_positions = []
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ‰‹è‡‚æˆ–æ‰‹æŒå•†å“
    has_interaction = len(arm_boxes) > 0 or len(hand_boxes) > 0
    
    if has_interaction:
        # éå†æ‰€æœ‰æ£€æµ‹åˆ°çš„é¢œè‰²
        for label, box_list in boxes_dict.items():
            if label in COLOR_POSITION_MAP:
                row, col = COLOR_POSITION_MAP[label]
                # æ‰¾åˆ°è¯¥é¢œè‰²æ¡†ä¸­ç½®ä¿¡åº¦æœ€é«˜çš„
                if box_list:
                    best_box = max(box_list, key=lambda x: x['conf'])
                    detected_positions.append((row, col, label, best_box['conf']))
    
    return detected_positions

# ä¸»ç•Œé¢ - è§†é¢‘é¢„æµ‹
st.markdown('<h2 class="sub-header">ğŸ“¹ è§†é¢‘æ™ºèƒ½é¢„æµ‹æ¼”ç¤º</h2>', unsafe_allow_html=True)

if model_path is None:
    st.warning("âš ï¸ è¯·å…ˆè®¾ç½®æ¨¡å‹è·¯å¾„")
else:
    model = load_model_safe(model_dir=model_path)
    
    if model is not None:
        # è§†é¢‘ä¸Šä¼ 
        uploaded_video = st.file_uploader("é€‰æ‹©è§†é¢‘æ–‡ä»¶", type=['mp4', 'avi', 'mov', 'mkv'])
        
        if uploaded_video is not None:
            # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                tmp_file.write(uploaded_video.read())
                video_path = tmp_file.name
            
            # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
            cap = cv2.VideoCapture(video_path)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            cap.release()
            
            st.info(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {width}x{height} @ {fps:.1f}fps, æ€»å¸§æ•°: {total_frames}")
            # st.info(f"ğŸ¯ å½“å‰è´¨é‡è®¾ç½®: {video_quality}% | å®æ—¶æ˜¾ç¤º: {'å¼€å¯' if realtime_display else 'å…³é—­'}")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                if st.button("ğŸš€ å¼€å§‹è§†é¢‘é¢„æµ‹", type="primary"):
                    # åˆ›å»ºè¿›åº¦æ¡
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # è§†é¢‘å¤„ç†
                    cap = cv2.VideoCapture(video_path)
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    
                    # åˆ›å»ºè¾“å‡ºè§†é¢‘ï¼ˆä¼˜åŒ–è´¨é‡è®¾ç½®ï¼‰
                    output_video_path = "output_prediction.mp4"
                    
                    # æ ¹æ®è´¨é‡è®¾ç½®é€‰æ‹©åˆé€‚çš„ç¼–ç å™¨
                    encoding_options = [
                        ('H264', cv2.VideoWriter_fourcc(*'H264')),  # H.264ç¼–ç ï¼ˆæœ€å…¼å®¹ï¼‰
                        ('mp4v', cv2.VideoWriter_fourcc(*'mp4v')),  # MPEG-4ç¼–ç 
                        ('XVID', cv2.VideoWriter_fourcc(*'XVID')),  # XVIDç¼–ç 
                        ('MJPG', cv2.VideoWriter_fourcc(*'MJPG')),  # Motion JPEGç¼–ç 
                    ]
                    
                    # å°è¯•ä¸åŒçš„ç¼–ç å™¨
                    out = None
                    for codec_name, fourcc in encoding_options:
                        try:
                            test_out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
                            if test_out.isOpened():
                                out = test_out
                                break
                            else:
                                test_out.release()
                        except:
                            continue
                    
                    if out is None:
                        st.error("âŒ æ— æ³•åˆå§‹åŒ–è§†é¢‘ç¼–ç å™¨ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿæ”¯æŒ")
                        st.stop()
                    
                    # è®¾ç½®è§†é¢‘è´¨é‡å‚æ•°ï¼ˆä½¿ç”¨å®‰å…¨çš„å±æ€§è®¾ç½®ï¼‰
                    try:
                        # å°è¯•è®¾ç½®è´¨é‡å‚æ•°ï¼Œå¦‚æœå±æ€§ä¸å­˜åœ¨åˆ™å¿½ç•¥
                        if hasattr(cv2, 'VIDEOWRITER_PROP_QUALITY'):
                            out.set(cv2.VIDEOWRITER_PROP_QUALITY, video_quality)
                    except:
                        pass  # å¿½ç•¥æ‰€æœ‰ç›¸å…³é”™è¯¯
                    
                    # é¢„æµ‹çŠ¶æ€å˜é‡
                    count = 0
                    frame_idx = 0
                    pickup_frame_map = {}
                    log_data = []
                    
                    # è¡Œåˆ—ç»Ÿè®¡æ•°æ®
                    row_col_stats = {}  # {(row, col): count}
                    pickup_details = []  # è®°å½•æ¯æ¬¡æ‹¿å–çš„è¯¦ç»†ä¿¡æ¯
                    
                    # åˆå§‹åŒ–å¤šäººæ£€æµ‹å™¨ï¼ˆç»Ÿä¸€ä½¿ç”¨ï¼Œå…¼å®¹å•äººå’Œå¤šäººåœºæ™¯ï¼‰
                    multi_detector = MultiPersonDetector(
                        action_window=multi_action_window,
                        arm_thresh=multi_arm_thresh,
                        handGoods_thresh=multi_handGoods_thresh,
                        arm_miss_limit=multi_arm_miss_limit,
                        cooldown_limit=multi_cooldown_limit,
                        iou_threshold=multi_iou_threshold
                    )
                    
                    # åˆ›å»ºè§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
                    video_placeholder = st.empty()
                    
                    while cap.isOpened():
                        ret, frame = cap.read()
                        if not ret:
                            break
                        frame_idx += 1
                        
                        # æ›´æ–°è¿›åº¦æ¡
                        progress = frame_idx / total_frames
                        progress_bar.progress(progress)
                        status_text.text(f"å¤„ç†è¿›åº¦: {frame_idx}/{total_frames} å¸§ ({progress:.1%})")
                        
                        # PaddleDetectioné¢„æµ‹
                        results = model.predict(frame, verbose=False, save=False, show=False, 
                                               conf=confidence_threshold, iou=0.5, 
                                               imgsz=640, half=False)
                        frame_labels = set()
                        scores = {}
                        arm_boxes = []
                        hand_boxes = []
                        color_boxes = {}  # å­˜å‚¨å„é¢œè‰²çš„æ£€æµ‹æ¡†
                        
                        for result in results:
                            for box in result.boxes:
                                label = result.names[int(box.cls)]
                                conf = float(box.conf)
                                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                                
                                if conf >= confidence_threshold:
                                    if label not in scores or conf > scores[label]:
                                        scores[label] = conf
                                    
                                    if label == "arm":
                                        arm_boxes.append((x1, y1, x2, y2))
                                    elif label == "handGoods":
                                        hand_boxes.append((x1, y1, x2, y2))
                                    
                                # æ”¶é›†é¢œè‰²æ¡†ä¿¡æ¯
                                if label in COLOR_POSITION_MAP:
                                    if label not in color_boxes:
                                        color_boxes[label] = []
                                    color_boxes[label].append({'conf': conf, 'box': (x1, y1, x2, y2)})
                                
                                frame_labels.add(label)
                        
                        # ä½¿ç”¨å¤šäººæ£€æµ‹å™¨å¤„ç†å¸§ï¼ˆç»Ÿä¸€å¤„ç†å•äººå’Œå¤šäººåœºæ™¯ï¼‰
                        prev_count = count
                        detection_result = multi_detector.process_frame(frame_idx, arm_boxes, hand_boxes)
                        count = detection_result["total_count"]
                        pickup_frame_map[frame_idx] = count
                        
                        # æ£€æµ‹åˆ°æ–°çš„æ‹¿å–åŠ¨ä½œæ—¶ï¼Œåˆ†æé¢œè‰²ä½ç½®
                        if count > prev_count:
                            detected_positions = analyze_drawer_colors(color_boxes, arm_boxes, hand_boxes)
                            if detected_positions:
                                # æš‚å­˜ä½ç½®è¯†åˆ«æ•°æ®ï¼ˆä»…ä¿å­˜ç½®ä¿¡åº¦é«˜äºé˜ˆå€¼çš„è®°å½•ï¼Œç­‰å¾…åç«¯ä¿®æ­£ï¼‰
                                for row, col, color, conf_score in detected_positions:
                                    # åº”ç”¨ç½®ä¿¡åº¦è¿‡æ»¤
                                    if conf_score >= position_confidence_threshold:
                                        pickup_details.append({
                                            'frame': frame_idx,
                                            'timestamp': format_timestamp(frame_idx, fps),
                                            'row': row,
                                            'col': col,
                                            'color': color,
                                            'confidence': round(conf_score, 2)
                                        })
                        
                        # ç»˜åˆ¶é¢„æµ‹ç»“æœ
                        rendered_img = None
                        try:
                            for result in results:
                                # ä½¿ç”¨æ ‡å‡†ç»˜åˆ¶ï¼ˆé€‚ä¸­çº¿å®½å’Œå­—ä½“ï¼Œæ¸…æ™°ä½†ä¸çªå…€ï¼‰
                                rendered_img = result.plot(line_width=3, font_size=24, 
                                                         conf=True, labels=True)
                                
                                # æ£€æŸ¥å›¾åƒæ˜¯å¦æœ‰æ•ˆ
                                if rendered_img is not None and hasattr(rendered_img, 'shape') and len(rendered_img.shape) >= 2:
                                    try:
                                        # è®¡ç®—æ–‡å­—ä½ç½®ï¼ˆæ°´å¹³å±…ä¸­ï¼‰
                                        img_height, img_width = rendered_img.shape[:2]
                                        
                                        # æ ¹æ®å›¾åƒå®½åº¦åŠ¨æ€è°ƒæ•´æ–‡å­—ä½ç½®ï¼ˆæ°´å¹³å±…ä¸­ï¼‰
                                        font_size = 28
                                        text_content = f"è¯¥é¡¾å®¢æ‹¿å–æ€»å•†å“æ•°ä¸º: {count}"
                                        
                                        # æ›´ç²¾ç¡®çš„æ–‡å­—å®½åº¦ä¼°ç®—
                                        chinese_chars = len([c for c in text_content if '\u4e00' <= c <= '\u9fff'])
                                        other_chars = len(text_content) - chinese_chars
                                        estimated_text_width = chinese_chars * font_size + other_chars * font_size * 0.6
                                        
                                        # è®¡ç®—æ°´å¹³å±…ä¸­ä½ç½®
                                        text_x = (img_width - int(estimated_text_width)) // 2
                                        text_y = 50
                                        
                                        # ç¡®ä¿æ–‡å­—ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
                                        text_x = max(10, min(text_x, img_width - int(estimated_text_width)))
                                        text_y = max(30, min(text_y, img_height - 10))
                                        
                                        # ç»˜åˆ¶æ€»æ‹¿å–æ•°é‡ï¼ˆå•äººå’Œå¤šäººæ£€æµ‹ç»Ÿä¸€æ˜¾ç¤ºï¼‰
                                        rendered_img = draw_chinese_text(rendered_img,
                                                                         f"é¡¾å®¢æ‹¿å–æ€»å•†å“æ•°ä¸º: {count}",
                                                                         position=(text_x, text_y),
                                                                         font_size=28,
                                                                         color=(0, 255, 0))
                                    except Exception as e:
                                        pass
                                
                            # ç¡®ä¿æœ‰å›¾åƒå¯ä»¥å†™å…¥
                            if rendered_img is not None:
                                out.write(rendered_img)
                            else:
                                out.write(frame)
                        except Exception as e:
                            # å¦‚æœæ•´ä¸ªç»˜åˆ¶è¿‡ç¨‹å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å¸§
                            out.write(frame)
                        
                        # å®æ—¶æ˜¾ç¤ºå½“å‰å¸§
                        if realtime_display:
                            try:
                                display_img = None
                                if rendered_img is not None and hasattr(rendered_img, 'shape'):
                                    display_img = rendered_img.copy()
                                else:
                                    display_img = frame.copy()
                            
                                if resize_display and hasattr(display_img, 'shape') and len(display_img.shape) >= 2:
                                    height, width = display_img.shape[:2]
                                    if width > 800:
                                        ratio = 800 / width
                                        new_width = 800
                                        new_height = int(height * ratio)
                                        display_img = cv2.resize(display_img, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)
                                
                                # ç¡®ä¿é¢œè‰²æ ¼å¼æ­£ç¡®
                                if len(display_img.shape) == 3 and display_img.shape[2] == 3:
                                    display_img = cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB)
                                
                                # æ˜¾ç¤ºå½“å‰å¤„ç†çŠ¶æ€ï¼ˆå¢å¼ºçš„ä¿¡æ¯æ˜¾ç¤ºï¼‰
                                fsm1_count = detection_result.get("fsm1_count", 0)
                                fsm2_count = detection_result.get("fsm2_count", 0)
                                active_persons = len(detection_result.get("active_persons", []))
                                caption_text = f"ğŸ¯ è§†é¢‘æ£€æµ‹ | å¸§: {frame_idx}/{total_frames} | æ€»æ‹¿å–æ•°: {count} | æ´»è·ƒäººæ•°: {active_persons}"
                                
                                video_placeholder.image(display_img, caption=caption_text, 
                                                      use_container_width=True, channels="RGB")
                            except Exception as e:
                                pass
                        
                        # è®°å½•æ—¥å¿—æ•°æ®
                        timestamp = format_timestamp(frame_idx, fps)
                        log_data.append([
                            timestamp,
                            round(scores.get("arm", 0), 2) if "arm" in scores else 0,
                            round(scores.get("handGoods", 0), 2) if "handGoods" in scores else 0,
                            pickup_frame_map.get(frame_idx, 0)
                        ])
                    
                    cap.release()
                    out.release()
                    
                    # ========== åç«¯æ•°æ®ä¿®æ­£ï¼šç¡®ä¿ä½ç½®è¯†åˆ«æ€»æ•°=æ‹¿å–æ€»æ•° ==========
                    # ä¿®æ­£ç­–ç•¥ï¼šæ‹¿å–æ€»æ•°ä¸å˜ï¼Œè°ƒæ•´ä½ç½®è¯†åˆ«æ•°æ®ä½¿å…¶ç­‰äºæ‹¿å–æ€»æ•°
                    
                    initial_position_count = len(pickup_details)
                    
                    # æƒ…å†µ1ï¼šä½ç½®è¯†åˆ«æ•° > æ‹¿å–æ€»æ•° â†’ åˆ é™¤å¤šä½™çš„ï¼ˆä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„ï¼‰
                    if initial_position_count > count > 0:
                        # æŒ‰ç½®ä¿¡åº¦ä»é«˜åˆ°ä½æ’åºï¼Œåªä¿ç•™å‰Næ¡ï¼ˆN = æ‹¿å–æ€»æ•°ï¼‰
                        pickup_details = sorted(
                            pickup_details, 
                            key=lambda x: x['confidence'], 
                            reverse=True
                        )[:count]
                    
                    # æƒ…å†µ2ï¼šä½ç½®è¯†åˆ«æ•° < æ‹¿å–æ€»æ•° â†’ æ— æ³•åˆ›é€ æ•°æ®ï¼Œä¿æŒåŸæ ·
                    # ï¼ˆè¿™ç§æƒ…å†µè¯´æ˜éƒ¨åˆ†æ‹¿å–åŠ¨ä½œæœªè¯†åˆ«åˆ°ä½ç½®ï¼Œå±äºæ­£å¸¸ç°è±¡ï¼‰
                    
                    # æƒ…å†µ3ï¼šä½ç½®è¯†åˆ«æ•° = æ‹¿å–æ€»æ•° â†’ ä¸éœ€è¦ä¿®æ­£
                    
                    # åŸºäºä¿®æ­£åçš„pickup_detailsé‡æ–°è®¡ç®—row_col_stats
                    row_col_stats = {}
                    for detail in pickup_details:
                        key = (detail['row'], detail['col'])
                        row_col_stats[key] = row_col_stats.get(key, 0) + 1
                    
                    # åç«¯éªŒè¯
                    final_position_count = len(pickup_details)
                    # print(f"[åç«¯ä¿®æ­£] æ‹¿å–æ€»æ•°: {count}, åŸå§‹ä½ç½®è¯†åˆ«: {initial_position_count}, ä¿®æ­£å: {final_position_count}, ç­‰äºæ‹¿å–æ€»æ•°: {final_position_count == count or final_position_count < count}")
                    
                    # ========== åç«¯ä¿®æ­£å®Œæˆ ==========
                    
                    # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
                    status_text.text("âœ… è§†é¢‘å¤„ç†å®Œæˆ!")
                    progress_bar.progress(1.0)
                    
                    # æ˜¾ç¤ºå¤„ç†ç»“æœæ‘˜è¦
                    st.success("ğŸ‰ è§†é¢‘å¤„ç†å®Œæˆï¼")
                    st.info(f"ğŸ“Š å¤„ç†æ‘˜è¦: å…±å¤„ç† {frame_idx} å¸§ï¼Œæ£€æµ‹åˆ° {count} æ¬¡æ‹¿å–åŠ¨ä½œ")
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ€»å¸§æ•°", f"{total_frames}")
                    with col2:
                        st.metric("æ£€æµ‹åˆ°çš„æ‹¿å–æ¬¡æ•°", f"{count}")
                    with col3:
                        st.metric("å¤„ç†æ—¶é•¿", f"{frame_idx/fps:.1f}ç§’")
                    
                    # æ˜¾ç¤ºè¡Œåˆ—ç»Ÿè®¡ä¿¡æ¯ï¼ˆåç«¯å·²ä¿®æ­£ï¼‰
                    if row_col_stats or pickup_details:
                        st.markdown("---")
                        st.markdown("### ğŸ—„ï¸ æ™ºèƒ½æŸœè¡Œåˆ—ç»Ÿè®¡")
                        
                        # æ˜¾ç¤ºé¢œè‰²æ˜ å°„è¯´æ˜
                        with st.expander("ğŸ“– é¢œè‰²ä½ç½®æ˜ å°„è¡¨", expanded=False):
                            st.markdown("""
                            **æ™ºèƒ½æŸœå¸ƒå±€: 6è¡Œ Ã— 2åˆ—**
                            
                            | è¡Œå· | ç¬¬1åˆ— | ç¬¬2åˆ— |
                            |------|-------|-------|
                            | 1 | argent | black |
                            | 2 | yellow | scarlet |
                            | 3 | green | red |
                            | 4 | grey | blue |
                            | 5 | orange | purple |
                            | 6 | cyan | darkBlue |
                            """)
                        
                        col_left, col_right = st.columns([1, 1])
                        
                        with col_left:
                            st.markdown("#### ğŸ“ å„è¡Œåˆ—æ‹¿å–ç»Ÿè®¡")
                            if row_col_stats:
                                # åˆ›å»º6è¡Œ2åˆ—çš„ç»Ÿè®¡è¡¨æ ¼
                                stats_data = []
                                for row in range(1, 7):
                                    row_data = {'è¡Œå·': row}
                                    for col in range(1, 3):
                                        key = (row, col)
                                        row_data[f'ç¬¬{col}åˆ—'] = row_col_stats.get(key, 0)
                                    stats_data.append(row_data)
                                
                                df_stats = pd.DataFrame(stats_data)
                                st.dataframe(df_stats, use_container_width=True, hide_index=True)
                                
                                # æ€»è®¡
                                total_by_position = sum(row_col_stats.values())
                                st.info(f"ğŸ“¦ å„ä½ç½®æ€»æ‹¿å–æ¬¡æ•°: {total_by_position}")
                                
                                # ç»˜åˆ¶ç®€å•çš„çƒ­åŠ›å›¾
                                try:
                                    import matplotlib.pyplot as plt
                                    import matplotlib
                                    matplotlib.use('Agg')
                                    
                                    # åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®çŸ©é˜µ
                                    heatmap_data = np.zeros((6, 2))
                                    for (row, col), count in row_col_stats.items():
                                        heatmap_data[row-1, col-1] = count
                                    
                                    # ç»˜åˆ¶çƒ­åŠ›å›¾
                                    fig, ax = plt.subplots(figsize=(4, 6))
                                    im = ax.imshow(heatmap_data, cmap='YlOrRd', aspect='auto')
                                    
                                    # è®¾ç½®åæ ‡è½´
                                    ax.set_xticks([0, 1])
                                    ax.set_xticklabels(['ç¬¬1åˆ—', 'ç¬¬2åˆ—'])
                                    ax.set_yticks(range(6))
                                    ax.set_yticklabels([f'ç¬¬{i+1}è¡Œ' for i in range(6)])
                                    
                                    # åœ¨æ¯ä¸ªæ ¼å­ä¸­æ˜¾ç¤ºæ•°å€¼
                                    for i in range(6):
                                        for j in range(2):
                                            text = ax.text(j, i, int(heatmap_data[i, j]),
                                                         ha="center", va="center", color="black", fontsize=12)
                                    
                                    ax.set_title("æ‹¿å–æ¬¡æ•°çƒ­åŠ›å›¾")
                                    plt.colorbar(im, ax=ax, label='æ‹¿å–æ¬¡æ•°')
                                    plt.tight_layout()
                                    
                                    st.pyplot(fig)
                                    plt.close(fig)
                                except Exception as e:
                                    pass  # å¦‚æœç»˜å›¾å¤±è´¥ï¼Œä¸å½±å“å…¶ä»–åŠŸèƒ½
                            else:
                                st.info("æœªæ£€æµ‹åˆ°å…·ä½“çš„è¡Œåˆ—ä½ç½®ä¿¡æ¯")
                        
                        with col_right:
                            st.markdown("#### ğŸ“‹ æ‹¿å–è¯¦æƒ…è®°å½•")
                            if pickup_details:
                                df_details = pd.DataFrame(pickup_details)
                                df_details = df_details[['timestamp', 'row', 'col', 'color', 'confidence']]
                                df_details.columns = ['æ—¶é—´æˆ³', 'è¡Œ', 'åˆ—', 'é¢œè‰²', 'ç½®ä¿¡åº¦']
                                st.dataframe(df_details, use_container_width=True, hide_index=True)
                                
                                # æŒ‰é¢œè‰²ç»Ÿè®¡
                                st.markdown("##### ğŸ¨ é¢œè‰²åˆ†å¸ƒ")
                                color_counts = df_details['é¢œè‰²'].value_counts()
                                for color, count in color_counts.items():
                                    row, col = COLOR_POSITION_MAP.get(color, (0, 0))
                                    st.write(f"â€¢ {color} (ç¬¬{row}è¡Œç¬¬{col}åˆ—): {count}æ¬¡")
                            else:
                                st.info("æœªæ£€æµ‹åˆ°æ‹¿å–è¯¦æƒ…")
                    
                    # æ˜¾ç¤ºå’Œä¸‹è½½å¤„ç†åçš„è§†é¢‘
                    if os.path.exists(output_video_path):
                        st.markdown("---")
                        st.markdown("### ğŸ¬ é¢„æµ‹è§†é¢‘å±•ç¤º")
                        
                        try:
                            # æ˜¾ç¤ºè§†é¢‘
                            with open(output_video_path, "rb") as file:
                                video_bytes = file.read()
                                
                            # ä½¿ç”¨æ›´å…¼å®¹çš„è§†é¢‘æ˜¾ç¤ºæ–¹å¼
                            st.video(video_bytes, format="video/mp4")
                            
                            # ä¸‹è½½æŒ‰é’®
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½å¤„ç†åçš„è§†é¢‘",
                                data=video_bytes,
                                file_name="processed_video.mp4",
                                mime="video/mp4"
                            )
                            
                        except Exception as e:
                            st.error(f"âŒ è§†é¢‘æ˜¾ç¤ºå¤±è´¥: {str(e)}")
                            st.info("ğŸ’¡ è¯·å°è¯•ä¸‹è½½è§†é¢‘æ–‡ä»¶åˆ°æœ¬åœ°æ’­æ”¾")
                            
                            # æä¾›ä¸‹è½½æŒ‰é’®
                            try:
                                with open(output_video_path, "rb") as file:
                                    video_bytes = file.read()
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è½½å¤„ç†åçš„è§†é¢‘",
                                    data=video_bytes,
                                    file_name="processed_video.mp4",
                                    mime="video/mp4"
                                )
                            except Exception as download_error:
                                st.error(f"âŒ ä¸‹è½½ä¹Ÿå¤±è´¥äº†: {str(download_error)}")
                    else:
                        st.error("âŒ è¾“å‡ºè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                    
                    # æ˜¾ç¤ºæ£€æµ‹æ—¥å¿—ï¼ˆåœ¨ä¸‹è½½è§†é¢‘ä¹‹åï¼‰
                    if log_data:
                        st.markdown("---")
                        st.markdown("### ğŸ“Š æ£€æµ‹æ—¥å¿—")
                        df = pd.DataFrame(log_data, columns=["æ—¶é—´æˆ³", "æ‰‹è‡‚ç½®ä¿¡åº¦", "æ‰‹éƒ¨å•†å“ç½®ä¿¡åº¦", "æ‹¿å–æ¬¡æ•°"])
                        st.dataframe(df.head(100), use_container_width=True)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(video_path):
                os.unlink(video_path)

# é¡µè„šä¿¡æ¯
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; margin-top: 2rem;'>
    <p>åŸºäºPaddleDetectionæ¨¡å‹çš„æ™ºèƒ½é›¶å”®æ£€æµ‹ç³»ç»Ÿ | è®©æ™ºèƒ½é›¶å”®"çœ‹å¾—æ¸…ï¼Œæ•°å¾—æ˜" | æ”¯æŒå®æ—¶è§†é¢‘æ£€æµ‹ + æ™ºèƒ½æŸœè¡Œåˆ—ç»Ÿè®¡</p>
    <p>ç³»ç»Ÿç‰ˆæœ¬: 3.1 (PaddlePaddle) | æ›´æ–°æ—¶é—´: """ + datetime.now().strftime("%Y-%m-%d %H:%M:%S") + """</p>
</div>
""", unsafe_allow_html=True)

